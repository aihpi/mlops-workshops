{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2db9cb3a-89b0-4d4b-9155-665542874975",
   "metadata": {},
   "source": [
    "# AI Service MLOPs Series: Docker\n",
    "## About us\n",
    "\n",
    "Welcome to the MLOps Series taught by AI Services from the Hasso-Plattner-Institute. We are a publicly funded project supported by the BMBF (Federal Ministry of Education and Research). Visit [our website](https://hpi.de/kisz) to learn more about our offerings and join our [AI Maker Community on Slack](https://join.aimaker.community) to keep track of our weekly workshops and paper readings.\n",
    "\n",
    "## About the series\n",
    "In this series of workshops we dive into the basics of Docker and try to give an intuitive understanding about how it can be used. As the series progresses, we will demonstrate how Docker can be used for ML projects for local development and for serving models using an API.\n",
    "\n",
    "## Part 3 - Docker Train and Docker Predict\n",
    "### Learning Goals\n",
    "After completing this part, you should ideally be able to answer the following questions:\n",
    "\n",
    "- ðŸ’½ How can I use bind mounts? What are docker volumes?\n",
    "- ðŸªº How can I keep Docker images small?\n",
    "\n",
    "### Introduction\n",
    "\n",
    "Important: https://docs.docker.com/storage/volumes/\n",
    "\n",
    "![](images/01.png)\n",
    "\n",
    "![](images/02.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5421e421-c5b1-4b68-be43-7e7d104db673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#0 building with \"default\" instance using docker driver\n",
      "\n",
      "#1 [internal] load build definition from Dockerfile\n",
      "#1 transferring dockerfile: 676B done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [internal] load metadata for docker.io/library/python:3.11-slim\n",
      "#2 DONE 0.4s\n",
      "\n",
      "#3 [internal] load .dockerignore\n",
      "#3 transferring context: 2B done\n",
      "#3 DONE 0.0s\n",
      "\n",
      "#4 [1/6] FROM docker.io/library/python:3.11-slim@sha256:dad770592ab3582ab2dabcf0e18a863df9d86bd9d23efcfa614110ce49ac20e4\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 [internal] load build context\n",
      "#5 transferring context: 108B done\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#6 [5/6] COPY language_detection.csv .\n",
      "#6 CACHED\n",
      "\n",
      "#7 [2/6] WORKDIR /app\n",
      "#7 CACHED\n",
      "\n",
      "#8 [3/6] COPY requirements.txt .\n",
      "#8 CACHED\n",
      "\n",
      "#9 [4/6] RUN pip install --no-cache -r requirements.txt\n",
      "#9 CACHED\n",
      "\n",
      "#10 [6/6] COPY train.py .\n",
      "#10 CACHED\n",
      "\n",
      "#11 exporting to image\n",
      "#11 exporting layers done\n",
      "#11 writing image sha256:6858a1b7c06390513ec9a9f5b6717e0a059096286793e9b24577cfcb3b6cd0c4 done\n",
      "#11 naming to docker.io/library/language-detection-trainer:solution-0.2 done\n",
      "#11 DONE 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming language Sweedish to Swedish ...\n",
      "Renaming language Portugeese to Portuguese ...\n",
      "# DATASET\n",
      "Dataset size: 10337 items, \n",
      "Train size: 8269 items, \n",
      "Test size: 2068 items\n",
      "\n",
      "# ACCURACY\n",
      "Train accuracy: 99.12%\n",
      "Test accuracy: 98.40%\n",
      "Saved model to models/multinomial_language_detector.joblib\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Clear trained model (if exists)\n",
    "sudo rm -f ./predict/models/multinomial_language_detector.joblib\n",
    "\n",
    "# Solution\n",
    "docker build -t language-detection-trainer:solution-0.2 -f train/solution/Dockerfile train\n",
    "docker run --rm -v ./predict/models:/app/models language-detection-trainer:solution-0.2\n",
    "\n",
    "# Exercise\n",
    "# docker build -t language-detection-trainer:0.2 train\n",
    "# docker run --rm -v ./predict/models:/app/models language-detection-trainer:0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74620731-2458-4049-a453-a8798079489e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#0 building with \"default\" instance using docker driver\n",
      "\n",
      "#1 [internal] load build definition from Dockerfile\n",
      "#1 transferring dockerfile: 678B done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [internal] load metadata for docker.io/library/python:3.11-slim\n",
      "#2 DONE 0.4s\n",
      "\n",
      "#3 [internal] load .dockerignore\n",
      "#3 transferring context: 2B done\n",
      "#3 DONE 0.0s\n",
      "\n",
      "#4 [1/6] FROM docker.io/library/python:3.11-slim@sha256:dad770592ab3582ab2dabcf0e18a863df9d86bd9d23efcfa614110ce49ac20e4\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 [internal] load build context\n",
      "#5 transferring context: 11.47MB 0.1s done\n",
      "#5 DONE 0.1s\n",
      "\n",
      "#6 [2/6] WORKDIR /app\n",
      "#6 CACHED\n",
      "\n",
      "#7 [3/6] COPY requirements.txt .\n",
      "#7 CACHED\n",
      "\n",
      "#8 [4/6] RUN pip install --no-cache -r requirements.txt\n",
      "#8 CACHED\n",
      "\n",
      "#9 [5/6] COPY models models\n",
      "#9 DONE 0.0s\n",
      "\n",
      "#10 [6/6] COPY predict.py .\n",
      "#10 DONE 0.0s\n",
      "\n",
      "#11 exporting to image\n",
      "#11 exporting layers\n",
      "#11 exporting layers 0.8s done\n",
      "#11 writing image sha256:3719f3e82b4fd9b9b10e5b0c4dfc12b5b4bf7a5da91216c030adbe122311ae61 done\n",
      "#11 naming to docker.io/library/language-detection-model:0.2 done\n",
      "#11 DONE 0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Already solved in previous task\n",
    "docker build -t language-detection-model:0.2 predict\n",
    "docker run --rm language-detection-model:0.2 \"Guten Tag\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
